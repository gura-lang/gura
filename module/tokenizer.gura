#!/usr/bin/env gura
import(re)

Entry = struct(pattern:re.pattern, func:function)

Tokenizer = class {
	__init__() = {
		self.mode = `start
		self.entriesDict = %{}
	}
	SetRule() {`block} = {
		self.entriesDict[`start] = self.ParseBlock(block)
	}
	SetMode(mode:symbol) = {
		self.mode = mode
	}
	Tokenize(stream:stream) = {
		raw = 0
		readlines(stream) {|lineBuff|
			col = 0
			while (col < lineBuff.len()) {
				self.match = nil
				for (entry in self.entriesDict[self.mode]) {
					if (self.match = entry.pattern.match(lineBuff, col)) {
						entry.func(self)
						col = self.match.end(0)
						break
					}
				}
				if (!self.match) {
					raise(ValueError,
						'unrecognizable token at %d:%d' % [raw + 1, col + 1])
					break
				}
			}
			raw += 1
		}
	}
	ParseBlock(block:expr) = {
		block.each():xlist {|expr|
			if (!expr.isdictassign()) {
				raise(SyntaxError, 'invalid element')
			} elsif (expr.left().isquote()) {
				exprLeft = expr.left().unquote()
				self.entriesDict[exprLeft.getsymbol()] = self.ParseBlock(expr.right())
				nil
			} else {
				Entry(re.pattern('^' + expr.left().getstring()), expr.right().tofunction())
			}
		}
	}
}
