#!program-gura/gura -I ../module -I ../module/site
import(helper.test) {*}
import(arrayt)
import(ml.mnist)

CalcMeanSquaredError(y:array, t:array) = ((y - t) ** 2).sum() / 2
CalcCrossEntropyError(y:array, t:array) = -(t * math.log(y + 1e-7)).sum()

db = ml.mnist.Database('../sample/resource/mnist')

weight = array@float.rands@normal([784, 10], 0, .1)
bias = array@float.rands@normal([1, 10], 0, .1)
model = `(x |.| weight + bias)
scope {
	arrImage = db.train.imageSet.ToArray(`flat)
	arrLabel = db.train.labelSet.ToArray()
	trainer(model, `x) {|tr|
		//y = tr.eval()
		repeat (100) {|iRepeat|
			repeat (1000) {|i|
				x = arrImage[i].reshape([1, nil])
				t = arrLabel[i].reshape([1, nil])
				tr.train(t)
			}
			printf('#%d error=%f\n', iRepeat + 1, CalcCrossEntropyError(tr.result, t))
		}
	}
}
scope {
	// evaluation
	arrImage = db.test.imageSet.ToArray(`flat)
	arrLabel = db.test.labelSet.ToArray()
	nTests = 200
	nCorrects = 0
	repeat (nTests) {|i|
		x = arrImage[i]
		t = arrLabel[i]
		y = model.eval() |*| filter@softmax()
		print(ml.mnist.ToAscii(x))
		if (y.argmax() == t.argmax()) {
			printf(' "%d" .. correct with likelihood %.1f%%\n', y.argmax(), y[y.argmax()] * 100)
			nCorrects += 1
		} else {
			printf(' "%d" .. wrong. correct is "%d"\n', y.argmax(), t.argmax())
		}
		println('-' * 70)
	}
	printf('accuracy: %d/%d (%.1f%%)\n', nCorrects, nTests, nCorrects / nTests * 100)
}
